# DeepSeek-R1-Distill-Qwen3-8B GRPOå¾®è°ƒæ•™ç¨‹

> è¯ä¸å¤šè¯´ï¼Œç›´æ¥å¼€å§‹ï¼

æœ¬æ–‡ä½¿ç”¨çš„æµ‹è¯•ç¯å¢ƒä¸ºå•å¼  A100ï¼Œæ˜¾å­˜ 80GBï¼Œå¯æ ¹æ®éœ€æ±‚åˆ‡æ¢ä¸åŒå‚æ•°é‡çš„æ¨¡å‹ï¼Œå®æµ‹4B 24Gæ˜¾å­˜ is enoughï¼
ä½¿ç”¨çš„æ¡†æ¶ä¸º Unsloth
![05-1](./images/05-1.png)
Unsloth æ˜¯ä¸€ä¸ªæå…¶å¼ºè°ƒèµ„æºèŠ‚çœçš„æ¡†æ¶ï¼ŒæŠŠæ‰€æœ‰çš„èµ„æºèŠ‚çœåšåˆ°äº†æè‡´ï¼Œå…·ä½“æ¥è®²Unslothèƒ½å¤Ÿå°† Llama-3ã€Mistralã€Phi-4 å’Œ Gemma ç­‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒé€Ÿåº¦æå‡ 2 å€ï¼Œå†…å­˜å ç”¨å‡å°‘ 70%ï¼Œå¹¶ä¸”å‡†ç¡®ç‡æ²¡æœ‰ä»»ä½•ä¸‹é™ï¼
å®˜æ–¹æ–‡æ¡£éå¸¸å…¨é¢ï¼Œè¯¦ç»†æŒ‡å¯¼äº†å¦‚ä½•è®­ç»ƒè‡ªå·±çš„å®šåˆ¶æ¨¡å‹ã€‚å…¶ä¸­æ¶µç›–äº†å®‰è£…å’Œæ›´æ–° Unslothã€åˆ›å»ºæ•°æ®é›†ã€è¿è¡Œå’Œéƒ¨ç½²æ¨¡å‹ç­‰åŸºæœ¬è¦ç´ ã€‚ Unsloth è®©å¤§å®¶åœ¨æœ¬åœ°æˆ–åœ¨ Google Colab å’Œ Kaggle ç­‰å¹³å°ä¸Šè®­ç»ƒåƒ Llama 3 è¿™æ ·çš„æ¨¡å‹å˜å¾—æå…¶ç®€å•ã€‚Unslothç®€åŒ–äº†æ•´ä¸ªè®­ç»ƒå·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹åŠ è½½ã€é‡åŒ–ã€è®­ç»ƒã€è¯„ä¼°ã€è¿è¡Œã€ä¿å­˜ã€å¯¼å‡ºï¼Œä»¥åŠä¸ Ollamaã€llama.cpp å’Œ vLLM ç­‰æ¨ç†å¼•æ“çš„é›†æˆã€‚
Unslothå®šæœŸä¸ Hugging Faceã€Google å’Œ Meta çš„å›¢é˜Ÿåˆä½œï¼Œä»¥ä¿®å¤ LLM è®­ç»ƒå’Œæ¨¡å‹ä¸­çš„é”™è¯¯ã€‚å› æ­¤ï¼Œå½“ä½¿ç”¨ Unsloth è¿›è¡Œè®­ç»ƒæˆ–ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œå¯ä»¥æœŸå¾…è·å¾—æœ€å‡†ç¡®çš„ç»“æœã€‚ Unsloth å…·æœ‰é«˜åº¦å¯å®šåˆ¶æ€§ï¼Œå…è®¸æ›´æ”¹èŠå¤©æ¨¡æ¿æˆ–æ•°æ®é›†æ ¼å¼ç­‰å†…å®¹ã€‚Unslothè¿˜ä¸ºè§†è§‰ã€æ–‡æœ¬è½¬è¯­éŸ³ (TTS)ã€BERTã€å¼ºåŒ–å­¦ä¹  (RL) ç­‰æä¾›äº†é¢„æ„å»ºçš„è„šæœ¬ï¼æ­¤å¤–ï¼ŒUnslothæ”¯æŒæ‰€æœ‰è®­ç»ƒæ–¹æ³•å’Œæ‰€æœ‰åŸºäº Transformer çš„æ¨¡å‹ã€‚

## æ•™ç¨‹æ¦‚è§ˆ

æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å®Œæˆ **DeepSeek-R1-Distill-Qwen3-8B æ¨¡å‹çš„ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰å¾®è°ƒ**ï¼Œè¿™æ˜¯ä¸€ç§å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œä¸“é—¨ç”¨äºæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

### ä»€ä¹ˆæ˜¯GRPOï¼Ÿ

GRPOï¼ˆGroup Relative Policy Optimizationï¼‰æ˜¯ä¸€ç§å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æŠ€æœ¯ï¼Œé€šè¿‡è®¾è®¡å¤šä¸ªå¥–åŠ±å‡½æ•°æ¥è¯„ä¼°æ¨¡å‹è¾“å‡ºçš„ä¸åŒæ–¹é¢ï¼Œä»è€ŒæŒ‡å¯¼æ¨¡å‹å­¦ä¹ æœŸæœ›çš„è¡Œä¸ºæ¨¡å¼ã€‚åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼ŒGRPOå¯ä»¥å¸®åŠ©æ¨¡å‹ï¼š

- å­¦ä¼šæŒ‰ç…§ç‰¹å®šæ ¼å¼è¾“å‡ºç­”æ¡ˆ
- æé«˜æ¨ç†è¿‡ç¨‹çš„é€»è¾‘æ€§
- å¢å¼ºç­”æ¡ˆçš„å‡†ç¡®æ€§
- æ”¹å–„è¾“å‡ºçš„ç»“æ„åŒ–ç¨‹åº¦

### æœ¬æ•™ç¨‹çš„å­¦ä¹ å†…å®¹

1. **ç¯å¢ƒè®¾ç½®**: å®‰è£…Unslothå’Œç›¸å…³ä¾èµ–
2. **æ¨¡å‹åŠ è½½**: åŠ è½½DeepSeek-R1-Distill-Qwen3-8Bé¢„è®­ç»ƒæ¨¡å‹
3. **LoRAé…ç½®**: è®¾ç½®é«˜æ•ˆçš„å‚æ•°å¾®è°ƒ
4. **æ•°æ®å¤„ç†**: å¤„ç†GSM8Kæ•°å­¦æ¨ç†æ•°æ®é›†
5. **æ ¼å¼è®¾è®¡**: å®šä¹‰ç»“æ„åŒ–çš„è¾“å‡ºæ ¼å¼
6. **å¥–åŠ±å‡½æ•°**: è®¾è®¡å¤šç»´åº¦è¯„ä¼°ä½“ç³»
7. **GRPOè®­ç»ƒ**: æ‰§è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒ
8. **æ•ˆæœéªŒè¯**: æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹
9. **æ¨¡å‹ä¿å­˜**: ä¿å­˜è®­ç»ƒç»“æœ
10. **å¯è§†åŒ–ç›‘æ§**: ä½¿ç”¨SwanLabè·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹




```python
# å®‰è£…ä¾èµ–åŒ…
# pip install unsloth vllm==0.8.5.post1
```

```python
# å®‰è£…è¯­è¨€æ£€æµ‹åº“
# pip install langid -qq
```

```python
from unsloth import FastLanguageModel
import torch
max_seq_length = 1024 
lora_rank = 32

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "/opt/tiger/test0/DeepSeek-R1-0528-Qwen3-8B",
    max_seq_length = max_seq_length,
    load_in_4bit = True, # å¯¹äºLoRA 16ä½è®¾ç½®ä¸ºFalse
    fast_inference = True, # å¯ç”¨vLLMå¿«é€Ÿæ¨ç†
    max_lora_rank = lora_rank,
    gpu_memory_utilization = 0.7, # å¦‚æœå†…å­˜ä¸è¶³è¯·å‡å°‘æ­¤å€¼
)

model = FastLanguageModel.get_peft_model(
    model,
    r = lora_rank, # é€‰æ‹©ä»»ä½•å¤§äº0çš„æ•°å­—ï¼å»ºè®®8, 16, 32, 64, 128
    target_modules = [
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj",
    ],
    lora_alpha = lora_rank*2, # *2å¯ä»¥åŠ é€Ÿè®­ç»ƒ
    use_gradient_checkpointing = "unsloth", # å‡å°‘å†…å­˜ä½¿ç”¨
    random_state = 3407,
)
```

### GRPOå¯¹è¯æ¨¡æ¿

```python
reasoning_start = None
reasoning_end = None
user_token = None
assistant_token = None

for token in tokenizer.get_added_vocab().keys():
    if "think" in token and "/" in token:
        reasoning_end = token
    elif "think" in token:
        reasoning_start = token
    elif "user" in token:
        user_token = token
    elif "assistant" in token:
        assistant_token = token

system_prompt = \
f"""ä½ æ¥åˆ°ä¸€ä¸ªé—®é¢˜ã€‚
è¯·æ€è€ƒè¿™ä¸ªé—®é¢˜å¹¶æä¾›ä½ çš„è§£é¢˜è¿‡ç¨‹ã€‚
ä½ å¿…é¡»ç”¨å°å°¼è¯­æ€è€ƒã€‚"""
system_prompt
```

```python
print(tokenizer.apply_chat_template([
    {"role" : "user", "content" : "What is 1+1?"},
    {"role" : "assistant", "content" : f"<think>I think it's 2.2</think>2"},
    {"role" : "user", "content" : "What is 1+1?"},
    {"role" : "assistant", "content" : f"<think>I think it's 2.2</think>2"},
], tokenize = False, add_generation_prompt = True))
```

### æ•°æ®å‡†å¤‡
```python
from datasets import load_dataset
dataset = load_dataset("open-r1/DAPO-Math-17k-Processed", "en", split = "train")
dataset
```

è®©æˆ‘ä»¬çœ‹çœ‹ç¬¬ä¸€è¡Œæ•°æ®ï¼š

```python
dataset[0]["prompt"]
```

```python
dataset[0]["solution"]
```

åœ¨GSM8Kä¸­ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°æ‰€æœ‰ç­”æ¡ˆéƒ½æœ‰####æ ‡è®°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æå–å®ƒã€‚ä½†å¯¹äºOpen R1æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥è·³è¿‡ä¸‹é¢çš„å¤„ç†ã€‚

```python
def extract_hash_answer(text):
    # if "####" not in text: return None
    # return text.split("####")[1].strip()
    return text
extract_hash_answer(dataset[0]["solution"])
```

è®©æˆ‘ä»¬æ˜ å°„æ•°æ®é›†ï¼å¹¶æŸ¥çœ‹ç¬¬ä¸€è¡Œï¼š

```python
dataset = dataset.map(lambda x: {
    "prompt" : [
        {"role": "system", "content": system_prompt},
        {"role": "user",   "content": x["prompt"]},
    ],
    "answer": extract_hash_answer(x["solution"]),
})
dataset[0]
```

æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ ¼å¼æ¥åŒ¹é…æ¨ç†éƒ¨åˆ†å’Œç­”æ¡ˆï¼š

```python
import re

# æ·»åŠ å¯é€‰çš„EOSæ ‡è®°åŒ¹é…
solution_end_regex = rf"{reasoning_end}(.*)"

match_format = re.compile(solution_end_regex, re.DOTALL)
match_format
```

æˆ‘ä»¬éªŒè¯å®ƒèƒ½æ­£å¸¸å·¥ä½œï¼š

```python
match_format.findall(
    "Let me think!</think>"\
    f"Hence, the solution is 2.",
)
```

```python
match_format.findall(
    "<think>Let me think!</think>"\
    f"\n\nHence, the solution is 2",
)
```

æˆ‘ä»¬ç°åœ¨è¦åˆ›å»ºä¸€ä¸ªå¥–åŠ±å‡½æ•°æ¥å®Œå…¨åŒ¹é…æ ¼å¼ - å¦‚æœæˆåŠŸåŒ¹é…æˆ‘ä»¬ç»™3åˆ†ï¼š

```python
def match_format_exactly(completions, **kwargs):
    scores = []
    for completion in completions:
        score = 0
        response = completion[0]["content"]
        # åŒ¹é…æ˜¯å¦å®Œå…¨ç¬¦åˆæ ¼å¼ï¼
        if match_format.search(response) is not None: score += 3.0
        scores.append(score)
    return scores
```

å¦‚æœå¤±è´¥ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è‡³å°‘éƒ¨åˆ†éµå¾ªæ ¼å¼æ—¶å¥–åŠ±æ¨¡å‹ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªç¬¦å·ï¼š

```python
def match_format_approximately(completions, **kwargs):
    scores = []
    for completion in completions:
        score = 0
        response = completion[0]["content"]
        # è®¡ç®—çœ‹åˆ°å¤šå°‘ä¸ªå…³é”®è¯ - å¦‚æœå¤ªå¤šæˆ‘ä»¬ä¼šæƒ©ç½šï¼
        # å¦‚æœæˆ‘ä»¬çœ‹åˆ°1ä¸ªï¼Œé‚£ä¹ˆåŠ ä¸€äº›åˆ†ï¼

        # ä¸éœ€è¦å¥–åŠ±<think>å› ä¸ºæˆ‘ä»¬æ€»æ˜¯é¢„ç½®å®ƒï¼
        score += 0.5 if response.count(reasoning_start) == 1 else -1.0
        score += 0.5 if response.count(reasoning_end)   == 1 else -1.0
        scores.append(score)
    return scores
```

æˆ‘ä»¬æƒ³è¦æå–ç”Ÿæˆçš„ç­”æ¡ˆï¼Œå¹¶å¥–åŠ±æˆ–æƒ©ç½šå®ƒï¼æˆ‘ä»¬è¿˜æ ¹æ®ç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆçš„æ¯”ç‡æ¥å¥–åŠ±ï¼š

```python
def check_answer(prompts, completions, answer, **kwargs):
    question = prompts[0][-1]["content"]
    responses = [completion[0]["content"] for completion in completions]

    extracted_responses = [
        guess.group(1)
        if (guess := match_format.search(r)) is not None else None \
        for r in responses
    ]

    scores = []
    for guess, true_answer in zip(extracted_responses, answer):
        score = 0
        if guess is None:
            scores.append(-2.0)
            continue
        # æ­£ç¡®ç­”æ¡ˆå¾—5åˆ†ï¼
        if guess == true_answer:
            score += 5.0
        # å¦‚æœçœ‹åˆ°ç©ºæ ¼ä½†å¥–åŠ±è¾ƒå°‘
        elif guess.strip() == true_answer.strip():
            score += 3.5
        else:
            # æˆ‘ä»¬ä¹Ÿé€šè¿‡æ¯”ç‡å¥–åŠ±æ¥è¿‘çš„ç­”æ¡ˆï¼
            # å³å¦‚æœç­”æ¡ˆåœ¨æŸä¸ªèŒƒå›´å†…ï¼Œå¥–åŠ±å®ƒï¼
            try:
                ratio = float(guess) / float(true_answer)
                if   ratio >= 0.9 and ratio <= 1.1: score += 2.0
                elif ratio >= 0.8 and ratio <= 1.2: score += 1.5
                else: score -= 2.5 # æƒ©ç½šé”™è¯¯ç­”æ¡ˆ
            except:
                score -= 4.5 # æƒ©ç½š
        scores.append(score)
    return scores
```

æœ‰æ—¶ç­”æ¡ˆå¯èƒ½ä¸æ˜¯1ä¸ªæ•°å­—ï¼Œè€Œæ˜¯åƒå¥å­ä¸€æ ·ï¼Œä¾‹å¦‚"è§£å†³æ–¹æ¡ˆæ˜¯$20" -> æˆ‘ä»¬æå–20ã€‚

æˆ‘ä»¬è¿˜ç§»é™¤å¯èƒ½çš„é€—å·ï¼Œä¾‹å¦‚123,456

```python
match_numbers = re.compile(
    r".*?[\s]{0,}([-]?[\d\.\,]{1,})",
    flags = re.MULTILINE | re.DOTALL
)
print(match_numbers.findall("  0.34  "))
print(match_numbers.findall("  123,456  "))
print(match_numbers.findall("  -0.234  "))
print(match_numbers.findall("17"))
```

æœ€åï¼Œæˆ‘ä»¬å°†å°è¯•å¼ºåˆ¶æ€è€ƒè¿‡ç¨‹ä½¿ç”¨å°å°¼è¯­ã€‚è¿™æ˜¯DeepSeek R1è®ºæ–‡ä¸­ä½¿ç”¨çš„`è¯­è¨€ä¸€è‡´æ€§å¥–åŠ±`çš„ç®€å•ç‰ˆæœ¬

```python
import langid

def get_lang(text: str) -> str:
    if not text:
        return "und"
    lang, _ = langid.classify(text)
    return lang


print(get_lang("Hello, How are you")) # è¿™åº”è¯¥è¿”å›en
print(get_lang("Aku berpikir kalau aku adalah kamu")) # è¿™åº”è¯¥è¿”å›id
print(get_lang("æˆ‘åœ¨è¿™é‡Œ")) # è¿™åº”è¯¥è¿”å›zh
```

```python
import re

def format_and_language_reward_func(completions, **kwargs):
    scores = []

    for completion_item in completions:
        if not completion_item or not isinstance(completion_item[0], dict) or "content" not in completion_item[0]:
            scores.append(-5.0)
            print(f"è­¦å‘Šï¼šæ ¼å¼é”™è¯¯çš„å®Œæˆé¡¹ï¼Œåˆ†é…é»˜è®¤ä½åˆ†: {completion_item}")
            continue

        content = completion_item[0]["content"]

        lang = get_lang(content)

        if lang == 'id':
            score = 5.0
        elif lang == 'en':
            score = -3.0
        elif lang == 'zh':
            score = -3.0
        else:
            score = -5.0

        scores.append(score)

    return scores
```

```python
prompts = [
    [{"role": "assistant", "content": "What is the result of (1 + 2) * 4?"}],
    [{"role": "assistant", "content": "What is the result of (3 + 1) * 2?"}],
]
completions = [
    [{"role": "assistant", "content": "<think>The sum of 1 and 2 is 3, which we multiply by 4 to get 12.</think><answer>(1 + 2) * 4 = 12</answer>"}],
    [{"role": "assistant", "content": "The sum of 3 and 1 is 4, which we multiply by 2 to get 8. So (3 + 1) * 2 = 8."}],
]
format_and_language_reward_func(prompts=prompts, completions=completions)
```

æˆ‘ä»¬ç°åœ¨å‡†å¤‡ä¸»å‡½æ•°ï¼Œå®ƒå°†æ‰“å°ç”Ÿæˆçš„å“åº”å’ŒçœŸå®ç­”æ¡ˆï¼Œä»¥åŠå¦ä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œé€šè¿‡`float`å°†æ–‡æœ¬è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶æŸ¥çœ‹æ˜¯å¦ç›¸åŒã€‚

```python
global PRINTED_TIMES
PRINTED_TIMES = 0
global PRINT_EVERY_STEPS
PRINT_EVERY_STEPS = 5

def check_numbers(prompts, completions, answer, **kwargs):
    question = prompts[0][-1]["content"]
    responses = [completion[0]["content"] for completion in completions]

    extracted_responses = [
        guess.group(1)
        if (guess := match_numbers.search(r)) is not None else None \
        for r in responses
    ]

    scores = []
    # åªåœ¨æ¯å‡ æ­¥æ‰“å°ä¸€æ¬¡
    global PRINTED_TIMES
    global PRINT_EVERY_STEPS
    if PRINTED_TIMES % PRINT_EVERY_STEPS == 0:
        print(
            '*'*20 + f"é—®é¢˜:\n{question}", f"\nç­”æ¡ˆ:\n{answer[0]}", f"\nå“åº”:\n{responses[0]}", f"\næå–çš„:\n{extracted_responses[0]}"
        )
    PRINTED_TIMES += 1

    for guess, true_answer in zip(extracted_responses, answer):
        if guess is None:
            scores.append(-2.5)
            continue
        # è½¬æ¢ä¸ºæ•°å­—
        try:
            true_answer = float(true_answer.strip())
            # ç§»é™¤é€—å·ï¼Œå¦‚123,456
            guess       = float(guess.strip().replace(",", ""))
            scores.append(3.5 if guess == true_answer else -1.5)
        except:
            scores.append(0)
            continue
    return scores
```

è·å–å‰90%çš„æç¤ºé•¿åº¦ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸ä¼šæ„å¤–æˆªæ–­å®ƒä»¬ï¼

å³æˆ‘ä»¬å°†ç§»é™¤å‰10%çš„é•¿æç¤ºã€‚

```python
tokenized = dataset.map(
    lambda x: {"tokens" : tokenizer.apply_chat_template(x["prompt"], add_generation_prompt = True, tokenize = True)},
    batched = True,
)
print(tokenizer.decode(tokenized[0]["tokens"]))
tokenized = tokenized.map(lambda x: {"L" : len(x["tokens"])})

import numpy as np
maximum_length = int(np.quantile(tokenized["L"], 0.9))
print("æœ€å¤§é•¿åº¦ = ", maximum_length)

# åªè¿‡æ»¤å°äº90%æœ€å¤§é•¿åº¦çš„æ ·æœ¬
dataset = dataset.select(np.where(np.array(tokenized["L"]) <= maximum_length)[0])
del tokenized
```

<a name="Train"></a>
### è®­ç»ƒæ¨¡å‹

ç°åœ¨è®¾ç½®GRPOè®­ç»ƒå™¨å’Œæ‰€æœ‰é…ç½®ï¼

```python
max_prompt_length = maximum_length + 1 # +1ä»¥é˜²ä¸‡ä¸€ï¼
max_completion_length = max_seq_length - max_prompt_length

from vllm import SamplingParams
vllm_sampling_params = SamplingParams(
    min_p = 0.1,
    top_p = 1.0,
    top_k = -1,
    seed = 3407,
    stop = [tokenizer.eos_token],
    include_stop_str_in_output = True,
)

from trl import GRPOConfig, GRPOTrainer
training_args = GRPOConfig(
    vllm_sampling_params = vllm_sampling_params,
    temperature = 1.0,
    learning_rate = 5e-6,
    weight_decay = 0.01,
    warmup_ratio = 0.1,
    lr_scheduler_type = "linear",
    optim = "adamw_8bit",
    logging_steps = 1,
    per_device_train_batch_size = 1,
    gradient_accumulation_steps = 1, # å¢åŠ åˆ°4ä»¥è·å¾—æ›´å¹³æ»‘çš„è®­ç»ƒ
    num_generations = 4, # å¦‚æœå†…å­˜ä¸è¶³è¯·å‡å°‘
    max_prompt_length = max_prompt_length,
    max_completion_length = max_completion_length,
    # num_train_epochs = 1, # å¯¹äºå®Œæ•´è®­ç»ƒè¿è¡Œè®¾ç½®ä¸º1
    max_steps = 100,
    save_steps = 100,
    report_to = "swanlab", # å¯ä»¥ä½¿ç”¨Weights & Biases
    output_dir = "outputs",

    # ç”¨äºå¯é€‰çš„è®­ç»ƒ+è¯„ä¼°
    # fp16_full_eval = True,
    # per_device_eval_batch_size = 4,
    # eval_accumulation_steps = 1,
    # eval_strategy = "steps",
    # eval_steps = 1,
)
```

è®©æˆ‘ä»¬è¿è¡Œè®­ç»ƒå™¨ï¼å¦‚æœä½ å‘ä¸Šæ»šåŠ¨ï¼Œä½ ä¼šçœ‹åˆ°ä¸€ä¸ªå¥–åŠ±è¡¨æ ¼ã€‚ç›®æ ‡æ˜¯çœ‹åˆ°`reward`åˆ—å¢åŠ ï¼

ä½ å¯èƒ½éœ€è¦ç­‰å¾…150åˆ°200æ­¥æ‰èƒ½çœ‹åˆ°ä»»ä½•æ•ˆæœã€‚å‰100æ­¥ä½ å¯èƒ½ä¼šå¾—åˆ°0å¥–åŠ±ã€‚è¯·è€å¿ƒç­‰å¾…ï¼

| æ­¥éª¤ | è®­ç»ƒæŸå¤± | å¥–åŠ±    | å¥–åŠ±æ ‡å‡†å·® | å®Œæˆé•¿åº¦        | kl       |
|------|---------------|-----------|------------|-------------------|----------|
| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |
| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |
| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |

```python
# ç”¨äºå¯é€‰çš„è®­ç»ƒ+è¯„ä¼°
# new_dataset = dataset.train_test_split(test_size = 0.01)

trainer = GRPOTrainer(
    model = model,
    processing_class = tokenizer,
    reward_funcs = [
        match_format_exactly,
        match_format_approximately,
        check_answer,
        check_numbers,
        format_and_language_reward_func,
    ],
    args = training_args,
    train_dataset = dataset,

    # ç”¨äºå¯é€‰çš„è®­ç»ƒ+è¯„ä¼°
    # train_dataset = new_dataset["train"],
    # eval_dataset = new_dataset["test"],
)
trainer.train()
```

<a name="Inference"></a>
### æ¨ç†
ç°åœ¨è®©æˆ‘ä»¬è¯•è¯•åˆšåˆšè®­ç»ƒçš„æ¨¡å‹ï¼é¦–å…ˆï¼Œè®©æˆ‘ä»¬å…ˆè¯•è¯•æ²¡æœ‰ç»è¿‡GRPOè®­ç»ƒçš„æ¨¡å‹ï¼š

```python
text = "What is the sqrt of 101?"

from vllm import SamplingParams
sampling_params = SamplingParams(
    temperature = 1.0,
    top_k = 50,
    max_tokens = 1024,
)
output = model.fast_generate(
    [text],
    sampling_params = sampling_params,
    lora_request = None,
)[0].outputs[0].text

output
```

ç°åœ¨ä½¿ç”¨æˆ‘ä»¬åˆšåˆšç”¨GRPOè®­ç»ƒçš„LoRA - æˆ‘ä»¬é¦–å…ˆä¿å­˜LoRAï¼

```python
model.save_lora("grpo_lora")
```

éªŒè¯LoRAç¡®å®è¢«è®­ç»ƒäº†ï¼

```python
from safetensors import safe_open

tensors = {}
with safe_open("grpo_lora/adapter_model.safetensors", framework = "pt") as f:
    # éªŒè¯Aå’ŒBéƒ½éé›¶
    for key in f.keys():
        tensor = f.get_tensor(key)
        n_zeros = (tensor == 0).sum() / tensor.numel()
        assert(n_zeros.item() != tensor.numel())
```

ç°åœ¨æˆ‘ä»¬åŠ è½½LoRAå¹¶æµ‹è¯•ã€‚æˆ‘ä»¬åœ¨ä¸ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºçš„æƒ…å†µä¸‹è¿›è¡Œæµ‹è¯•ï¼Œè¿™åº”è¯¥ä¸ä¼šï¼ˆæˆ–å¾ˆå°‘ï¼‰å½±å“æ¨¡å‹çš„åŸå§‹æ¨ç†èƒ½åŠ›ï¼š

```python
messages = [
    {"role": "user",   "content": "Solve (x + 2)^2 = 0"},
]

text = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt = True, # ç”Ÿæˆæ—¶å¿…é¡»æ·»åŠ 
    tokenize = False,
)
from vllm import SamplingParams
sampling_params = SamplingParams(
    temperature = 1.0,
    top_k = 50,
    max_tokens = 2048,
)
output = model.fast_generate(
    text,
    sampling_params = sampling_params,
    lora_request = model.load_lora("grpo_lora"),
)[0].outputs[0].text

output
```

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ç³»ç»Ÿæç¤ºè¿›è¡Œæµ‹è¯•ï¼Œè¿™åº”è¯¥ä½¿ç”¨æ–°è¯­è¨€ï¼š

```python
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user",   "content": "Solve (x + 2)^2 = 0"},
]

text = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt = True, # ç”Ÿæˆæ—¶å¿…é¡»æ·»åŠ 
    tokenize = False,
)
from vllm import SamplingParams
sampling_params = SamplingParams(
    temperature = 1.0,
    top_k = 50,
    max_tokens = 2048,
)
output = model.fast_generate(
    text,
    sampling_params = sampling_params,
    lora_request = model.load_lora("grpo_lora"),
)[0].outputs[0].text

output
```

è®©æˆ‘ä»¬æ¯”è¾ƒä½¿ç”¨ç³»ç»Ÿæç¤ºä½†ä¸ä½¿ç”¨LoRAçš„ç»“æœ

```python
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user",   "content": "Solve (x + 2)^2 = 0"},
]

text = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt = True, # ç”Ÿæˆæ—¶å¿…é¡»æ·»åŠ 
    tokenize = False,
)
from vllm import SamplingParams
sampling_params = SamplingParams(
    temperature = 1.0,
    top_k = 50,
    max_tokens = 2048,
)
output = model.fast_generate(
    text,
    sampling_params = sampling_params,
    lora_request = None,
)[0].outputs[0].text

output
```

è®©æˆ‘ä»¬å–20ä¸ªæ ·æœ¬ï¼Œæ¯”è¾ƒä½¿ç”¨LoRAå’Œä¸ä½¿ç”¨LoRAçš„æƒ…å†µï¼Œçœ‹çœ‹å“ªä¸€ä¸ªæœ‰æ›´å¥½çš„æ­£ç¡®è¯­è¨€ä½¿ç”¨é‡

```python
sample_dataset = dataset.shuffle(seed = 3407).select(range(20))
sample_dataset
```

```python
with_lora_id_count = 0
without_lora_id_count = 0

print("åœ¨20ä¸ªæ ·æœ¬ä¸Šæ¯”è¾ƒä½¿ç”¨å’Œä¸ä½¿ç”¨LoRAçš„è¯­è¨€ä½¿ç”¨æƒ…å†µ:")
print("=" * 60)

for i, sample in enumerate(sample_dataset):
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": sample["prompt"][1]["content"]},
    ]

    text = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        tokenize=False,
    )

    output_with_lora = model.fast_generate(
        text,
        sampling_params=sampling_params,
        lora_request=model.load_lora("grpo_lora"),
    )[0].outputs[0].text

    output_without_lora = model.fast_generate(
        text,
        sampling_params=sampling_params,
        lora_request=None,
    )[0].outputs[0].text

    lang_with_lora = get_lang(output_with_lora)
    lang_without_lora = get_lang(output_without_lora)

    if lang_with_lora == 'id':
        with_lora_id_count += 1
    if lang_without_lora == 'id':
        without_lora_id_count += 1

    # æ¯5ä¸ªæ ·æœ¬æ‰“å°è¿›åº¦
    if (i + 1) % 5 == 0:
        print(f"å·²å¤„ç† {i + 1}/20 ä¸ªæ ·æœ¬...")

print("\n" + "=" * 60)
print("ç»“æœ:")
print(f"ä½¿ç”¨LoRA - å°å°¼è¯­å“åº”: {with_lora_id_count}/20 ({with_lora_id_count/20*100:.1f}%)")
print(f"ä¸ä½¿ç”¨LoRA - å°å°¼è¯­å“åº”: {without_lora_id_count}/20 ({without_lora_id_count/20*100:.1f}%)")
print(f"æ”¹è¿›: ä½¿ç”¨LoRAå¢åŠ äº†{with_lora_id_count - without_lora_id_count}ä¸ªå°å°¼è¯­å“åº”")
```

æˆ‘ä»¬çš„æ¨ç†æ¨¡å‹è¦å¥½å¾—å¤š - å®ƒä¸æ€»æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºæˆ‘ä»¬åªè®­ç»ƒäº†å¤§çº¦ä¸€ä¸ªå°æ—¶ - å¦‚æœæˆ‘ä»¬å»¶é•¿åºåˆ—é•¿åº¦å¹¶è®­ç»ƒæ›´é•¿æ—¶é—´ä¼šæ›´å¥½ï¼

<a name="Save"></a>
### ä¿å­˜ä¸ºfloat16æ ¼å¼ç”¨äºVLLM

æˆ‘ä»¬è¿˜æ”¯æŒç›´æ¥ä¿å­˜ä¸º`float16`ã€‚é€‰æ‹©`merged_16bit`ç”¨äºfloat16æˆ–`merged_4bit`ç”¨äºint4ã€‚æˆ‘ä»¬è¿˜å…è®¸`lora`é€‚é…å™¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆã€‚ä½¿ç”¨`push_to_hub_merged`ä¸Šä¼ åˆ°ä½ çš„Hugging Faceè´¦æˆ·ï¼ä½ å¯ä»¥å»https://huggingface.co/settings/tokensè·å–ä½ çš„ä¸ªäººä»¤ç‰Œã€‚

```python
# åˆå¹¶ä¸º16ä½
if False: model.save_pretrained_merged("model", tokenizer, save_method = "merged_16bit",)
if False: model.push_to_hub_merged("hf/model", tokenizer, save_method = "merged_16bit", token = "")

# åˆå¹¶ä¸º4ä½
if False: model.save_pretrained_merged("model", tokenizer, save_method = "merged_4bit",)
if False: model.push_to_hub_merged("hf/model", tokenizer, save_method = "merged_4bit", token = "")

# ä»…LoRAé€‚é…å™¨
if False:
    model.save_pretrained("model")
    tokenizer.save_pretrained("model")
if False:
    model.push_to_hub("hf/model", token = "")
    tokenizer.push_to_hub("hf/model", token = "")
```

### GGUF / llama.cpp è½¬æ¢
è¦ä¿å­˜ä¸º`GGUF` / `llama.cpp`ï¼Œæˆ‘ä»¬ç°åœ¨åŸç”Ÿæ”¯æŒå®ƒï¼æˆ‘ä»¬å…‹éš†`llama.cpp`å¹¶é»˜è®¤ä¿å­˜ä¸º`q8_0`ã€‚æˆ‘ä»¬å…è®¸æ‰€æœ‰æ–¹æ³•ï¼Œå¦‚`q4_k_m`ã€‚ä½¿ç”¨`save_pretrained_gguf`è¿›è¡Œæœ¬åœ°ä¿å­˜ï¼Œä½¿ç”¨`push_to_hub_gguf`ä¸Šä¼ åˆ°HFã€‚

ä¸€äº›æ”¯æŒçš„é‡åŒ–æ–¹æ³•ï¼ˆå®Œæ•´åˆ—è¡¨åœ¨æˆ‘ä»¬çš„[Wikié¡µé¢](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)ï¼‰ï¼š
* `q8_0` - å¿«é€Ÿè½¬æ¢ã€‚é«˜èµ„æºä½¿ç”¨ï¼Œä½†é€šå¸¸å¯æ¥å—ã€‚
* `q4_k_m` - æ¨èã€‚å¯¹ä¸€åŠçš„attention.wvå’Œfeed_forward.w2å¼ é‡ä½¿ç”¨Q6_Kï¼Œå…¶ä»–ä½¿ç”¨Q4_Kã€‚
* `q5_k_m` - æ¨èã€‚å¯¹ä¸€åŠçš„attention.wvå’Œfeed_forward.w2å¼ é‡ä½¿ç”¨Q6_Kï¼Œå…¶ä»–ä½¿ç”¨Q5_Kã€‚

[**æ–°åŠŸèƒ½**] è¦å¾®è°ƒå¹¶è‡ªåŠ¨å¯¼å‡ºåˆ°Ollamaï¼Œè¯•è¯•æˆ‘ä»¬çš„[Ollamaç¬”è®°æœ¬](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)

```python
# ä¿å­˜ä¸º8ä½Q8_0
if False: model.save_pretrained_gguf("model", tokenizer,)
# è®°ä½å»https://huggingface.co/settings/tokensè·å–ä»¤ç‰Œï¼
# å¹¶å°†hfæ”¹ä¸ºä½ çš„ç”¨æˆ·åï¼
if False: model.push_to_hub_gguf("hf/model", tokenizer, token = "")

# ä¿å­˜ä¸º16ä½GGUF
if False: model.save_pretrained_gguf("model", tokenizer, quantization_method = "f16")
if False: model.push_to_hub_gguf("hf/model", tokenizer, quantization_method = "f16", token = "")

# ä¿å­˜ä¸ºq4_k_m GGUF
if False: model.save_pretrained_gguf("model", tokenizer, quantization_method = "q4_k_m")
if False: model.push_to_hub_gguf("hf/model", tokenizer, quantization_method = "q4_k_m", token = "")

# ä¿å­˜ä¸ºå¤šä¸ªGGUFé€‰é¡¹ - å¦‚æœä½ æƒ³è¦å¤šä¸ªé€‰é¡¹ä¼šå¿«å¾ˆå¤šï¼
if False:
    model.push_to_hub_gguf(
        "hf/model", # å°†hfæ”¹ä¸ºä½ çš„ç”¨æˆ·åï¼
        tokenizer,
        quantization_method = ["q4_k_m", "q8_0", "q5_k_m",],
        token = "",
    )
```


### æœ¬è¯•éªŒçš„è¯•éªŒè®°å½•

#### GRPOé˜¶æ®µ

![05-3](./images/05-3.png)
400ä¸ªstepä¹‹ålossä¼šæœ‰æ˜æ˜¾å˜åŒ–

## æ•™ç¨‹æ€»ç»“

ğŸ‰ æ­å–œï¼ä½ å·²ç»æˆåŠŸå®Œæˆäº†DeepSeek-R1-Distill-Qwen3-8Bçš„GRPOå¾®è°ƒæ•™ç¨‹ã€‚

### æœ¬æ•™ç¨‹æ¶µç›–çš„æ ¸å¿ƒæ¦‚å¿µï¼š

1. **GRPOå¾®è°ƒ**: ä½¿ç”¨å¥–åŠ±å‡½æ•°æŒ‡å¯¼æ¨¡å‹å­¦ä¹ ç‰¹å®šè¾“å‡ºæ ¼å¼
2. **LoRAæŠ€æœ¯**: é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ–¹æ³•ï¼ŒèŠ‚çœæ˜¾å­˜å’Œæ—¶é—´
3. **å¥–åŠ±å‡½æ•°è®¾è®¡**: å¤šå±‚æ¬¡è¯„ä¼°ä½“ç³»ï¼Œä»æ ¼å¼åˆ°å†…å®¹çš„å…¨é¢è¯„ä»·
4. **ç»“æ„åŒ–è¾“å‡º**: è®­ç»ƒæ¨¡å‹æŒ‰ç…§ç‰¹å®šæ ¼å¼è¾“å‡ºæ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
5. **SwanLabç›‘æ§**: å®æ—¶è·Ÿè¸ªè®­ç»ƒè¿›åº¦å’ŒæŒ‡æ ‡å˜åŒ–

### å­¦åˆ°çš„æŠ€èƒ½ï¼š

- âœ… è®¾ç½®GRPOè®­ç»ƒç¯å¢ƒ
- âœ… è®¾è®¡å¤šç»´åº¦å¥–åŠ±å‡½æ•°
- âœ… é…ç½®LoRAå‚æ•°è¿›è¡Œé«˜æ•ˆå¾®è°ƒ
- âœ… å¤„ç†æ•°å­¦æ¨ç†æ•°æ®é›†
- âœ… ç›‘æ§å’Œåˆ†æè®­ç»ƒè¿‡ç¨‹
- âœ… ä¿å­˜å’Œéƒ¨ç½²å¾®è°ƒæ¨¡å‹

### è¿›ä¸€æ­¥æ¢ç´¢ï¼š

1. **è°ƒæ•´å¥–åŠ±å‡½æ•°**: è®¾è®¡æ›´å¤æ‚çš„è¯„ä¼°æœºåˆ¶
2. **æ‰©å±•æ•°æ®é›†**: ä½¿ç”¨æ›´å¤§æˆ–ä¸åŒç±»å‹çš„æ•°æ®é›†
3. **ä¼˜åŒ–å‚æ•°**: å°è¯•ä¸åŒçš„LoRAé…ç½®å’Œè®­ç»ƒå‚æ•°
4. **æ¨¡å‹è¯„ä¼°**: åœ¨æµ‹è¯•é›†ä¸Šç³»ç»Ÿè¯„ä¼°æ¨¡å‹æ€§èƒ½
5. **åº”ç”¨éƒ¨ç½²**: å°†æ¨¡å‹é›†æˆåˆ°å®é™…åº”ç”¨ä¸­

### æ³¨æ„äº‹é¡¹ï¼š

- æœ¬æ•™ç¨‹ä½¿ç”¨äº†è¾ƒå°‘çš„è®­ç»ƒæ­¥æ•°ä½œä¸ºæ¼”ç¤ºï¼Œå®é™…åº”ç”¨ä¸­å»ºè®®ä½¿ç”¨æ›´å¤šæ­¥æ•°
- å¯ä»¥æ ¹æ®æ˜¾å­˜æƒ…å†µè°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œç”Ÿæˆæ•°é‡
- SwanLabæä¾›äº†ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½ï¼Œå»ºè®®æ·±å…¥æ¢ç´¢

æ„Ÿè°¢ä½ çš„å­¦ä¹ ï¼å¦‚æœæœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æŸ¥çœ‹SwanLabçš„å®éªŒè®°å½•æˆ–é‡æ–°è¿è¡Œä»£ç ã€‚

# æ€»ç»“

Congratulationsï¼çœ‹åˆ°äº†è¿™ï¼Œä½ å·²ç»åˆæ­¥å®ç°äº†ä¸€ä¸ªç®€å•çš„RLå®æˆ˜ï¼ŒæŒæ¡äº†ä½¿ç”¨ Unsloth å¯¹ Gemma3 è¿™ç±»å¤§æ¨¡å‹è¿›è¡Œ GRPO å¾®è°ƒçš„å…·ä½“æ“ä½œæ­¥éª¤ï¼Œæ›´èƒ½ä½“ä¼šåˆ° Unsloth åœ¨å¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦ã€æ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨æ–¹é¢çš„å¼ºå¤§ä¼˜åŠ¿ï¼Œä»è€Œä½¿åœ¨æœ‰é™èµ„æºä¸‹è¿›è¡Œå¤æ‚å¼ºåŒ–å­¦ä¹ å®éªŒæˆä¸ºå¯èƒ½ï¼å¦‚æœæ”¯æŒæˆ‘ä»¬çš„å·¥ä½œå¸Œæœ›å¾—åˆ°ä½ çš„starï¼ï¼è¿™æ˜¯æˆ‘ä»¬æŒç»­æ›´æ–°çš„æœ€å¤§åŠ¨åŠ›ï¼ï¼ï¼

# ç›¸å…³é“¾æ¥

- å®Œæ•´å¯è¿è¡Œçš„ä»£ç ï¼š[Github](https://github.com/datawhalechina/self-llm/blob/master/models/DeepSeek-R1-Distill-Qwen/05-DeepSeek-R1-Distill-Qwen3-8B-GRPOåŠswanlabå¯è§†åŒ–.ipynb)
- ç»¼è¿°ï¼šhttps://arxiv.org/abs/2001.06921
- deepseek-r1ï¼šhttps://arxiv.org/abs/2501.12948
- æ•°å­¦åŸç†ï¼šhttps://blog.csdn.net/weixin\_38991876/article/details/146474767
- Unslothï¼šhttps://docs.unsloth.ai/
