import os.path

import streamlit as st
import torch
from PIL import Image
from decord import VideoReader, cpu
import numpy as np
from transformers import AutoModel, AutoTokenizer

# æ¨¡å‹è·¯å¾„ - è¯·ç¡®ä¿è¯¥è·¯å¾„å­˜åœ¨ä¸”åŒ…å«æ­£ç¡®çš„æ¨¡å‹æ–‡ä»¶
model_path = '/root/autodl-tmp/OpenBMB/MiniCPM-o-2_6'
upload_path = "/root/autodl-tmp/upload"

# å¦‚æœä¸Šä¼ ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
os.makedirs(upload_path, exist_ok=True)

# ç”¨æˆ·å’ŒåŠ©æ‰‹çš„èŠå¤©ç•Œé¢åç§°
U_NAME = "User"
A_NAME = "Assistant"

# è®¾ç½®Streamlité¡µé¢é…ç½®
st.set_page_config(
    page_title="Self-LLM MiniCPM-V-2_6 Streamlit",
    page_icon=":robot:",
    layout="wide"
)

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼ˆä½¿ç”¨ç¼“å­˜ä»¥æé«˜æ€§èƒ½ï¼‰
@st.cache_resource
def load_model_and_tokenizer():
    print(f"load_model_and_tokenizer from {model_path}")
    model = (AutoModel.from_pretrained(model_path, 
                                       trust_remote_code=True, 
                                       attn_implementation='sdpa').
             to(dtype=torch.bfloat16))
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    return model, tokenizer


# å¦‚æœä¼šè¯çŠ¶æ€ä¸­æ²¡æœ‰æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œåˆ™è¿›è¡Œåˆå§‹åŒ–
if 'model' not in st.session_state:
    st.session_state.model, st.session_state.tokenizer = load_model_and_tokenizer()
    st.session_state.model.eval().cuda()
    print("model and tokenizer had loaded completed!")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ä¸­çš„èŠå¤©å†å²å’Œåª’ä½“è¿½è¸ª
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
    st.session_state.uploaded_image_list = []
    st.session_state.uploaded_image_num = 0
    st.session_state.uploaded_video_list = []
    st.session_state.uploaded_video_num = 0
    st.session_state.response = ""

# ä¾§è¾¹æ é…ç½®

# åœ¨ä¾§è¾¹æ åˆ›å»ºæ ‡é¢˜å’Œé“¾æ¥
with st.sidebar:
    st.title("[å¼€æºå¤§æ¨¡å‹ä½¿ç”¨æŒ‡å—](https://github.com/datawhalechina/self-llm.git)")
    
# åˆ›å»ºä¸»æ ‡é¢˜å’Œå‰¯æ ‡é¢˜
st.title("ğŸ’¬ MiniCPM-V-2_6 ChatBot")
st.caption("ğŸš€ A streamlit chatbot powered by Self-LLM")

# åˆ›å»ºæœ€å¤§é•¿åº¦å‚æ•°æ»‘å—ï¼ˆ0-4096ï¼Œé»˜è®¤2048ï¼‰
max_length = st.sidebar.slider("max_length", 0, 4096, 2048, step=2)

# æ¨¡å‹ç”Ÿæˆå‚æ•°è®¾ç½®
repetition_penalty = st.sidebar.slider("repetition_penalty", 0.0, 2.0, 1.05, step=0.01)
top_k = st.sidebar.slider("top_k", 0, 100, 100, step=1)
top_p = st.sidebar.slider("top_p", 0.0, 1.0, 0.8, step=0.01)
temperature = st.sidebar.slider("temperature", 0.0, 1.0, 0.7, step=0.01)

# æ¸…é™¤ä¼šè¯å†å²å¹¶é‡Šæ”¾å†…å­˜çš„æŒ‰é’®
buttonClean = st.sidebar.button("æ¸…é™¤ä¼šè¯å†å²", key="clean")
if buttonClean:
    # é‡ç½®æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡
    st.session_state.chat_history = []
    st.session_state.uploaded_image_list = []
    st.session_state.uploaded_image_num = 0
    st.session_state.uploaded_video_list = []
    st.session_state.uploaded_video_num = 0
    st.session_state.response = ""

    # å¦‚æœæœ‰GPUï¼Œæ¸…é™¤CUDAç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # åˆ·æ–°ç•Œé¢
    st.rerun()

# ä½¿ç”¨é€‚å½“çš„æ ¼å¼æ˜¾ç¤ºèŠå¤©å†å²
for i, message in enumerate(st.session_state.chat_history):
    if message["role"] == "user":
        with st.chat_message(name="user", avatar="user"):
            if message["image"] is not None:
                st.image(message["image"], caption='ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡', width=512, use_container_width=False)
                continue
            elif message["video"] is not None:
                st.video(message["video"], format="video/mp4", loop=False, autoplay=False, muted=True)
                continue
            elif message["content"] is not None:
                st.markdown(message["content"])
    else:
        with st.chat_message(name="model", avatar="assistant"):
            st.markdown(message["content"])

# æ¨¡å¼é€‰æ‹©ä¸‹æ‹‰èœå•
selected_mode = st.sidebar.selectbox("é€‰æ‹©æ¨¡å¼", ["æ–‡æœ¬", "å•å›¾ç‰‡", "å¤šå›¾ç‰‡", "è§†é¢‘"])

# å®šä¹‰æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
image_type = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']

# å•å›¾ç‰‡æ¨¡å¼é…ç½®
if selected_mode == "å•å›¾ç‰‡":
    uploaded_image = st.sidebar.file_uploader("ä¸Šä¼ å•å¼ å›¾ç‰‡", key=1, type=image_type,
                                              accept_multiple_files=False)
    if uploaded_image is not None:
        st.image(uploaded_image, caption='ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡', width=512, use_container_width=False)
        st.session_state.chat_history.append({"role": "user", "content": None, "image": uploaded_image, "video": None})
        st.session_state.uploaded_image_list = [uploaded_image]
        st.session_state.uploaded_image_num = 1

# å¤šå›¾ç‰‡æ¨¡å¼é…ç½®
if selected_mode == "å¤šå›¾ç‰‡":
    uploaded_image_list = st.sidebar.file_uploader("ä¸Šä¼ å¤šå¼ å›¾ç‰‡", key=2, type=image_type,
                                                   accept_multiple_files=True)
    uploaded_image_num = len(uploaded_image_list)

    if uploaded_image_list is not None and uploaded_image_num > 0:
        for img in uploaded_image_list:
            st.image(img, caption='ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡', width=512, use_container_width=False)
            st.session_state.chat_history.append({"role": "user", "content": None, "image": img, "video": None})
        st.session_state.uploaded_image_list = uploaded_image_list
        st.session_state.uploaded_image_num = uploaded_image_num

# å®šä¹‰æ”¯æŒçš„è§†é¢‘æ ¼å¼
video_type = ['.mp4', '.mkv', '.mov', '.avi', '.flv', '.wmv', '.webm', '.m4v']

# é‡è¦æç¤ºï¼šè¦å¤„ç†è¾ƒå¤§çš„è§†é¢‘æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œï¼š
# streamlit run ./web_demo_streamlit-minicpmv2_6.py --server.maxUploadSize 1024
# Streamlité»˜è®¤çš„200MBä¸Šä¼ é™åˆ¶å¯èƒ½ä¸è¶³ä»¥å¤„ç†è§†é¢‘
# è¯·æ ¹æ®å¯ç”¨çš„GPUå†…å­˜è°ƒæ•´å¤§å°

# è§†é¢‘æ¨¡å¼é…ç½®
if selected_mode == "è§†é¢‘":
    uploaded_video = st.sidebar.file_uploader("ä¸Šä¼ å•ä¸ªè§†é¢‘æ–‡ä»¶", 
                                              key=3, 
                                              type=video_type,
                                              accept_multiple_files=False)
    if uploaded_video is not None:
        try:
            # æ­£ç¡®å¤„ç†è§†é¢‘ä¿å­˜è·¯å¾„
            video_filename = os.path.basename(uploaded_video.name)
            uploaded_video_path = os.path.join(upload_path, video_filename)
            
            # å°†è§†é¢‘æ–‡ä»¶å†™å…¥ç£ç›˜
            with open(uploaded_video_path, "wb") as vf:
                vf.write(uploaded_video.getbuffer())
            
            # æ˜¾ç¤ºè§†é¢‘å¹¶æ›´æ–°ä¼šè¯çŠ¶æ€
            st.video(uploaded_video_path)
            st.session_state.chat_history.append({"role": "user", "content": None, "image": None, "video": uploaded_video_path})
            st.session_state.uploaded_video_list = [uploaded_video_path]
            st.session_state.uploaded_video_num = 1
            
        except Exception as e:
            st.error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™ï¼š{str(e)}")
            print(f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")

# è§†é¢‘å¤„ç†çš„æœ€å¤§å¸§æ•° - å¦‚æœé‡åˆ°CUDAå†…å­˜ä¸è¶³ï¼Œè¯·å‡å°‘æ­¤å€¼
MAX_NUM_FRAMES = 64

def encode_video(video_path):
    """
    å¯¹è§†é¢‘è¿›è¡Œç¼–ç ï¼Œä»¥å›ºå®šé€Ÿç‡é‡‡æ ·å¸§å¹¶è½¬æ¢ä¸ºå›¾åƒæ•°ç»„ã€‚
    å®ç°å‡åŒ€é‡‡æ ·ä»¥åœ¨å†…å­˜é™åˆ¶ä¸‹å¤„ç†è¾ƒé•¿è§†é¢‘ã€‚
    """
    def uniform_sample(frame_indices, num_samples):
        # è®¡ç®—å‡åŒ€åˆ†å¸ƒçš„é‡‡æ ·é—´éš”
        gap = len(frame_indices) / num_samples
        sampled_idxs = np.linspace(gap / 2, len(frame_indices) - gap / 2, num_samples, dtype=int)
        return [frame_indices[i] for i in sampled_idxs]

    # åœ¨CPUä¸Šåˆå§‹åŒ–è§†é¢‘è¯»å–å™¨
    vr = VideoReader(video_path, ctx=cpu(0))

    # ä»¥1FPSé‡‡æ ·å¸§
    sample_fps = round(vr.get_avg_fps() / 1)
    frame_idx = list(range(0, len(vr), sample_fps))

    # å¦‚æœå¸§æ•°è¶…è¿‡æœ€å¤§å€¼ï¼Œè¿›è¡Œå‡åŒ€é‡‡æ ·
    if len(frame_idx) > MAX_NUM_FRAMES:
        frame_idx = uniform_sample(frame_idx, MAX_NUM_FRAMES)

    # å°†å¸§è½¬æ¢ä¸ºPILå›¾åƒæ ¼å¼
    frames = vr.get_batch(frame_idx).asnumpy()
    frames = [Image.fromarray(frame.astype('uint8')) for frame in frames]

    print('å¸§æ•°ï¼š', len(frames))
    return frames

# èŠå¤©è¾“å…¥å¤„ç†
user_text = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
if user_text is not None:
    if user_text.strip() == "":
        st.warning('è¾“å…¥æ¶ˆæ¯ä¸èƒ½ä¸ºç©ºï¼', icon="âš ï¸")
    else:
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message(U_NAME, avatar="user"):
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_text,
                "image": None,
                "video": None
            })
            st.markdown(f"{U_NAME}: {user_text}")

        # ä½¿ç”¨æ¨¡å‹å¤„ç†å“åº”
        model = st.session_state.model
        tokenizer = st.session_state.tokenizer
        content_list = []  # å­˜å‚¨æ¨¡å‹è¾“å…¥å†…å®¹çš„åˆ—è¡¨
        imageFile = None

        with st.chat_message(A_NAME, avatar="assistant"):
            # å¤„ç†ä¸åŒçš„è¾“å…¥æ¨¡å¼
            if selected_mode == "å•å›¾ç‰‡":
                print("ä½¿ç”¨å•å›¾ç‰‡æ¨¡å¼")
                if len(st.session_state.chat_history) > 1 and len(st.session_state.uploaded_image_list) >= 1:
                    uploaded_image = st.session_state.uploaded_image_list[-1]
                    if uploaded_image:
                        imageFile = Image.open(uploaded_image).convert('RGB')
                        content_list.append(imageFile)
                else:
                    print("å•å›¾ç‰‡æ¨¡å¼ï¼šæœªæ‰¾åˆ°å›¾ç‰‡")

            elif selected_mode == "å¤šå›¾ç‰‡":
                print("ä½¿ç”¨å¤šå›¾ç‰‡æ¨¡å¼")
                if len(st.session_state.chat_history) > 1 and st.session_state.uploaded_image_num >= 1:
                    for uploaded_image in st.session_state.uploaded_image_list:
                        imageFile = Image.open(uploaded_image).convert('RGB')
                        content_list.append(imageFile)
                else:
                    print("å¤šå›¾ç‰‡æ¨¡å¼ï¼šæœªæ‰¾åˆ°å›¾ç‰‡")

            elif selected_mode == "è§†é¢‘":
                print("ä½¿ç”¨è§†é¢‘æ¨¡å¼")
                if len(st.session_state.chat_history) > 1 and st.session_state.uploaded_video_num == 1:
                    uploaded_video_path = st.session_state.uploaded_video_list[-1]
                    if uploaded_video_path:
                        with st.spinner('æ­£åœ¨ç¼–ç è§†é¢‘ï¼Œè¯·ç¨å€™...'):
                            frames = encode_video(uploaded_video_path)
                else:
                    print("è§†é¢‘æ¨¡å¼ï¼šæœªæ‰¾åˆ°è§†é¢‘")

            # é…ç½®æ¨¡å‹ç”Ÿæˆå‚æ•°
            params = {
                'sampling': True,
                'top_p': top_p,
                'top_k': top_k,
                'temperature': temperature,
                'repetition_penalty': repetition_penalty,
                "max_new_tokens": max_length,
                "stream": True
            }

            # æ ¹æ®è¾“å…¥æ¨¡å¼è®¾ç½®å‚æ•°
            if st.session_state.uploaded_video_num == 1 and selected_mode == "è§†é¢‘":
                msgs = [{"role": "user", "content": frames + [user_text]}]
                # è§†é¢‘æ¨¡å¼ç‰¹å®šå‚æ•°
                params["max_inp_length"] = 4352  # è§†é¢‘æ¨¡å¼çš„æœ€å¤§è¾“å…¥é•¿åº¦
                params["use_image_id"] = False  # ç¦ç”¨å›¾åƒID
                params["max_slice_nums"] = 1  # å¦‚æœé«˜åˆ†è¾¨ç‡è§†é¢‘å‡ºç°CUDAå†…å­˜ä¸è¶³ï¼Œè¯·å‡å°æ­¤å€¼
            else:
                content_list.append(user_text)
                msgs = [{"role": "user", "content": content_list}]

            print("content_list:", content_list)  # è°ƒè¯•ä¿¡æ¯
            print("params:", params)  # è°ƒè¯•ä¿¡æ¯

            # ç”Ÿæˆå¹¶æ˜¾ç¤ºæ¨¡å‹å“åº”
            with st.spinner('AIæ­£åœ¨æ€è€ƒ...'):
                response = model.chat(image=None, msgs=msgs, context=None, tokenizer=tokenizer, **params)
            st.session_state.response = st.write_stream(response)
            st.session_state.chat_history.append({
                "role": "model",
                "content": st.session_state.response,
                "image": None,
                "video": None
            })

        # æ·»åŠ è§†è§‰åˆ†éš”ç¬¦
        st.divider()

