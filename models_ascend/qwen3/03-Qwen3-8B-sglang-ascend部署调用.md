# Qwen3-8B sglang-ascendéƒ¨ç½²è°ƒç”¨


## ç¯å¢ƒå‡†å¤‡

æœ¬æ–‡åŸºç¡€ç¯å¢ƒå¦‚ä¸‹ï¼š

```
----------------
ubuntu 22.04
NPUé©±åŠ¨ 25.2.0
python 3.11
cann 8.2.RC1
torch 2.6.0
torch-npu 2.6.0
----------------
```

> æœ¬æ–‡é»˜è®¤å­¦ä¹ è€…å·²é…ç½®å¥½ä»¥ä¸Š `Pytorch (CANN)` ç¯å¢ƒï¼Œå¦‚æœªé…ç½®è¯·å…ˆè‡ªè¡Œå®‰è£…ã€‚

> è¯·ç¡®å®šæ˜‡è…¾NPUèŠ¯ç‰‡çš„ç‰ˆæœ¬ï¼Œç›®å‰æ”¯æŒA2å’ŒA3ç³»åˆ—äº§å“ã€‚

## ç¯å¢ƒæ­å»º

### Python ç‰ˆæœ¬

```python
conda create --name sglang_npu python=3.11
conda activate sglang_npu
```

`pip` æ¢æºåŠ é€Ÿä¸‹è½½å¹¶å®‰è£…ä¾èµ–åŒ…

```
python -m pip install --upgrade pip
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
pip install modelscope
```



### Pytorch-npu å®‰è£…

```python
PYTORCH_VERSION=2.6.0
TORCHVISION_VERSION=0.21.0
TORCH_NPU_VERSION=2.6.0.post3
pip install torch==$PYTORCH_VERSION torchvision==$TORCHVISION_VERSION --index-url https://download.pytorch.org/whl/cpu
pip install torch_npu==$TORCH_NPU_VERSION
```

### å®‰è£… Deep-ep ä¸ sgl-kernel-npu

```
pip install wheel==0.45.1

git clone https://github.com/sgl-project/sgl-kernel-npu.git

#æ·»åŠ ç¯å¢ƒå˜é‡
export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/runtime/lib64/stub:$LD_LIBRARY_PATH
source /usr/local/Ascend/ascend-toolkit/set_env.sh

#ç¼–è¯‘å¹¶å®‰è£…deep-epä¸ sgl-kernel-npu
cd sgl-kernel-npu
bash build.sh
pip install output/deep_ep*.whl output/sgl_kernel_npu*.whl --no-cache-dir
```

### æºç å®‰è£… SGLang

```
git clone -b v0.5.3rc0 https://github.com/sgl-project/sglang.git

cd sglang

pip install -e python[srt_npu]
```

## æ¨¡å‹ä¸‹è½½

ä½¿ç”¨ modelscope ä¸­çš„ snapshot_download å‡½æ•°ä¸‹è½½æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å‹åç§°ï¼Œå‚æ•° cache_dir ä¸ºæ¨¡å‹çš„ä¸‹è½½è·¯å¾„ã€‚

æ–°å»º `model_download.py` æ–‡ä»¶å¹¶åœ¨å…¶ä¸­è¾“å…¥ä»¥ä¸‹å†…å®¹ï¼Œç²˜è´´ä»£ç åè®°å¾—ä¿å­˜æ–‡ä»¶ã€‚

```python
from modelscope import snapshot_download

model_dir = snapshot_download('Qwen/Qwen3-8B', cache_dir='/root/autodl-tmp', revision='master')
```

ç„¶ååœ¨ç»ˆç«¯ä¸­è¾“å…¥ `python model_download.py` æ‰§è¡Œä¸‹è½½ï¼Œè¿™é‡Œéœ€è¦è€å¿ƒç­‰å¾…ä¸€æ®µæ—¶é—´ç›´åˆ°æ¨¡å‹ä¸‹è½½å®Œæˆã€‚

> æ³¨æ„ï¼šè®°å¾—ä¿®æ”¹ `cache_dir` ä¸ºä½ çš„æ¨¡å‹ä¸‹è½½è·¯å¾„å“¦~

## åˆ›å»ºå…¼å®¹ OpenAI API æ¥å£çš„æœåŠ¡å™¨

`Qwen3-8B` å…¼å®¹ `OpenAI API` åè®®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨  `sglang-ascend`åœ¨æ˜‡è…¾æœåŠ¡å™¨ä¸Šåˆ›å»º`OpenAI API` æœåŠ¡å™¨æ¥å£ã€‚

åœ¨åˆ›å»ºæœåŠ¡å™¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ¨¡å‹åç§°ã€æ¨¡å‹è·¯å¾„ã€èŠå¤©æ¨¡æ¿ç­‰å‚æ•°ã€‚

- `--host` å’Œ `--port`ï¼š å‚æ•°æŒ‡å®šåœ°å€ã€‚
- `--model-path`ï¼šæœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚
- `attention-backend`ï¼šæŒ‡å®šåº•å±‚æ³¨æ„åŠ›è®¡ç®—ä½¿ç”¨çš„ç¡¬ä»¶åç«¯

```
python3 -m sglang.launch_server --model-path autodl-tmp/Qwen/Qwen3-8B --attention-backend ascend --host 0.0.0.0 --port 30000
```

è¿™æ ·å°±ç®—å¯åŠ¨æˆåŠŸï¼ï¼ï¼

![03-01](./images/03-01.png)


- é€šè¿‡ `curl` å‘½ä»¤æŸ¥çœ‹å½“å‰çš„æ¨¡å‹åˆ—è¡¨

```bash
curl http://localhost:30000/v1/models
```



å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º

```json
{
  "object": "list",
  "data": [
    {
      "id": "autodl-tmp/Qwen/Qwen3-8B",
      "object": "model",
      "created": 1768025296,
      "owned_by": "sglang",
      "root": "autodl-tmp/Qwen/Qwen3-8B",
      "max_model_len": 40960
    }
  ]
}
```

- ä½¿ç”¨ `curl` å‘½ä»¤æµ‹è¯• `OpenAI Completions API`

```bash
curl http://localhost:30000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen3-8B",
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼"}]
  }'
```

å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤º

```json
{
  "id": "556383264b9247c7a43369c6a82c2b29",
  "object": "chat.completion",
  "created": 1768025567,
  "model": "Qwen3-8B",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "<think>\nå¥½çš„ï¼Œç”¨æˆ·æ‰“æ‹›å‘¼è¯´â€œä½ å¥½ï¼â€ï¼Œæˆ‘éœ€è¦å‹å¥½å›åº”ã€‚é¦–å…ˆï¼Œè¦ä¿æŒè‡ªç„¶ï¼Œç”¨ä¸­æ–‡å›åº”ã€‚ç„¶åï¼Œå¯ä»¥è¯¢é—®ç”¨æˆ·ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Œæˆ–è€…æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©çš„ã€‚è¿™æ ·æ—¢äº²åˆ‡åˆä¸“ä¸šã€‚è¿˜è¦æ³¨æ„è¯­æ°”è¦æ¸©æš–ï¼Œé¿å…å¤ªè¿‡æœºæ¢°ã€‚å¯èƒ½éœ€è¦æ ¹æ®ç”¨æˆ·çš„åç»­é—®é¢˜è°ƒæ•´å›ç­”ï¼Œä½†å½“å‰åªéœ€è¦ä¸€ä¸ªåˆé€‚çš„å¼€åœºç™½ã€‚ç¡®ä¿æ²¡æœ‰ä½¿ç”¨ä»»ä½•Markdownæ ¼å¼ï¼Œä¿æŒå£è¯­åŒ–ã€‚\n</think>\n\nä½ å¥½ï¼ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·å‘€ï¼Ÿæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š",
        "reasoning_content": null,
        "tool_calls": null
      },
      "logprobs": null,
      "finish_reason": "stop",
      "matched_stop": 151645
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "total_tokens": 111,
    "completion_tokens": 101,
    "prompt_tokens_details": null,
    "reasoning_tokens": 0
  },
  "metadata": {
    "weight_version": "default"
  }
}
```

- ç”¨ `Python` è„šæœ¬è¯·æ±‚ `OpenAI Completions API`

```python
# vllm_openai_completions.py
from openai import OpenAI
client = OpenAI(
    base_url="http://localhost:3000/v1",
    api_key="sk-xxx", # éšä¾¿å¡«å†™ï¼Œåªæ˜¯ä¸ºäº†é€šè¿‡æ¥å£å‚æ•°æ ¡éªŒ
)

completion = client.chat.completions.create(
  model="Qwen3-8B",
  messages=[
    {"role": "user", "content": "ä½ å¥½\n"}
  ]
)

print(completion.choices[0].message)
```

```shell
python sglang_openai_completions.py
```

![03-02](./images/03-02.png)




## å‚è€ƒæ–‡ç« 

[å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ â€” æ˜‡è…¾å¼€æº æ–‡æ¡£](https://ascend.github.io/docs/sources/ascend/quick_install.html)

[å®‰è£…CANN-CANNç¤¾åŒºç‰ˆ8.3.RCX-æ˜‡è…¾ç¤¾åŒº](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/83RC1/softwareinst/instg/instg_0008.html?Mode=PmIns&InstallType=local&OS=openEuler&Software=cannToolKit)

[æ”¯æŒ NPU çš„ SGLang å®‰è£…æŒ‡å— â€” SGLang æ¡†æ¶](https://docs.sglang.com.cn/platforms/ascend_npu.html#python-version)

[sgl-kernel-npu/python/sgl_kernel_npu/README.md at main Â·SGL-project/SGL-kernel-npu](https://github.com/sgl-project/sgl-kernel-npu/blob/main/python/sgl_kernel_npu/README.md)
